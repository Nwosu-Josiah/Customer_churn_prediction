{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ISNhzfins6wn"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import warnings\n",
        "import numpy  as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.ensemble        import RandomForestClassifier\n",
        "from sklearn.linear_model    import LogisticRegression\n",
        "from sklearn.pipeline        import Pipeline\n",
        "from sklearn.compose         import ColumnTransformer\n",
        "from sklearn.preprocessing   import StandardScaler, OneHotEncoder\n",
        "from sklearn.model_selection import (\n",
        "    train_test_split,\n",
        "    RandomizedSearchCV,\n",
        "    StratifiedKFold,\n",
        "    cross_val_score,\n",
        ")\n",
        "from sklearn.metrics import (\n",
        "    roc_auc_score, roc_curve,\n",
        "    confusion_matrix, classification_report,\n",
        "    precision_score, recall_score, f1_score,\n",
        ")\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "np.random.seed(42)\n",
        "\n",
        "OUTPUT_DIR    = \"/content/model_outputs\"\n",
        "DATA_PATH     = \"/content/drive/MyDrive/rfm_features.csv\"\n",
        "SNAPSHOT_DATE = pd.Timestamp(\"2024-06-30\")\n",
        "\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\" * 60)\n",
        "print(\"STEP 1 — Loading data\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "df = pd.read_csv(DATA_PATH, parse_dates=[\"last_order_date\", \"registration_date\"])\n",
        "\n",
        "print(f\"  Rows loaded       : {len(df):,}\")\n",
        "print(f\"  Churned (label=1) : {df['churned'].sum():,}  ({df['churned'].mean()*100:.1f}%)\")\n",
        "print(f\"  Retained (label=0): {(df['churned']==0).sum():,}  ({(df['churned']==0).mean()*100:.1f}%)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHLFvj8HvUrC",
        "outputId": "da4c55e9-d4cd-4def-d81d-8c1f54610878"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "STEP 1 — Loading data\n",
            "============================================================\n",
            "  Rows loaded       : 5,000\n",
            "  Churned (label=1) : 3,184  (63.7%)\n",
            "  Retained (label=0): 1,816  (36.3%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"STEP 2 — Feature engineering\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Tenure in days — how long the customer has been registered\n",
        "df[\"tenure_days\"] = (SNAPSHOT_DATE - df[\"registration_date\"]).dt.days\n",
        "\n",
        "# Average monthly order rate — normalises frequency by tenure\n",
        "df[\"monthly_order_rate\"] = df[\"frequency\"] / (df[\"tenure_days\"] / 30).clip(lower=1)\n",
        "\n",
        "# Spend concentration — avg order value relative to total monetary value\n",
        "df[\"spend_per_order_ratio\"] = df[\"avg_order_value\"] / df[\"monetary\"].clip(lower=1)\n",
        "\n",
        "# Engagement breadth — distinct categories relative to total orders\n",
        "df[\"category_breadth_ratio\"] = df[\"distinct_categories\"] / df[\"frequency\"].clip(lower=1)\n",
        "\n",
        "# Discount dependency — total discounts as proportion of gross spend\n",
        "df[\"discount_dependency\"] = df[\"total_discounts\"] / (\n",
        "    df[\"monetary\"] + df[\"total_discounts\"]\n",
        ").clip(lower=1)\n",
        "\n",
        "engineered = [\n",
        "    \"tenure_days\", \"monthly_order_rate\", \"spend_per_order_ratio\",\n",
        "    \"category_breadth_ratio\", \"discount_dependency\",\n",
        "]\n",
        "print(\"  Engineered features:\")\n",
        "for feat in engineered:\n",
        "    print(f\"    + {feat}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsWb0nULvszI",
        "outputId": "8cf01a11-ae19-48f3-892d-5247ee2cc5ae"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "STEP 2 — Feature engineering\n",
            "============================================================\n",
            "  Engineered features:\n",
            "    + tenure_days\n",
            "    + monthly_order_rate\n",
            "    + spend_per_order_ratio\n",
            "    + category_breadth_ratio\n",
            "    + discount_dependency\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"STEP 3 — Defining feature set\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "NUMERIC_FEATURES = [\n",
        "    # Core RFM\n",
        "    \"recency_days\", \"frequency\", \"monetary\",\n",
        "    # Order behaviour\n",
        "    \"avg_order_value\", \"avg_delivery_days\", \"avg_review_score\",\n",
        "    # Refund behaviour\n",
        "    \"refund_rate\", \"refund_count\",\n",
        "    # Engagement\n",
        "    \"distinct_categories\", \"total_discounts\",\n",
        "    # RFM scores\n",
        "    \"R_score\", \"F_score\", \"M_score\",\n",
        "    # Engineered\n",
        "    \"tenure_days\", \"monthly_order_rate\", \"spend_per_order_ratio\",\n",
        "    \"category_breadth_ratio\", \"discount_dependency\",\n",
        "]\n",
        "\n",
        "CATEGORICAL_FEATURES = [\"state\", \"age_group\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eB4FKSi7x1GV",
        "outputId": "5412dcbf-1e2b-4a32-eca4-2d0e6cac6e52"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "STEP 3 — Defining feature set\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TARGET = \"churned\"\n",
        "\n",
        "X = df[NUMERIC_FEATURES + CATEGORICAL_FEATURES].copy()\n",
        "y = df[TARGET].copy()\n",
        "\n",
        "print(f\"  Numeric features    : {len(NUMERIC_FEATURES)}\")\n",
        "print(f\"  Categorical features: {len(CATEGORICAL_FEATURES)}\")\n",
        "print(f\"  Total features      : {len(NUMERIC_FEATURES) + len(CATEGORICAL_FEATURES)}\")\n",
        "print(f\"  Target              : {TARGET}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKQ4ZJx0yQEt",
        "outputId": "f5f087aa-bea4-48be-f071-277f5702f7fe"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Numeric features    : 18\n",
            "  Categorical features: 2\n",
            "  Total features      : 20\n",
            "  Target              : churned\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"STEP 4 — Train/test split\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.20, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(f\"  Split method : Stratified 80/20\")\n",
        "print(f\"  Train set    : {len(X_train):,} customers  (churn rate: {y_train.mean()*100:.1f}%)\")\n",
        "print(f\"  Test  set    : {len(X_test):,}  customers  (churn rate: {y_test.mean()*100:.1f}%)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bb13IHdMyZ8b",
        "outputId": "64a47d1b-15a5-479d-d504-271b088f4531"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "STEP 4 — Train/test split\n",
            "============================================================\n",
            "  Split method : Stratified 80/20\n",
            "  Train set    : 4,000 customers  (churn rate: 63.7%)\n",
            "  Test  set    : 1,000  customers  (churn rate: 63.7%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"STEP 5 — Building preprocessing pipeline\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "def make_preprocessor():\n",
        "    \"\"\"Return a fresh ColumnTransformer — needed for each pipeline clone.\"\"\"\n",
        "    return ColumnTransformer(transformers=[\n",
        "        (\"num\", StandardScaler(),\n",
        "         NUMERIC_FEATURES),\n",
        "        (\"cat\", OneHotEncoder(drop=\"first\", handle_unknown=\"ignore\"),\n",
        "         CATEGORICAL_FEATURES),\n",
        "    ], remainder=\"drop\")\n",
        "\n",
        "print(\"  Numeric      → StandardScaler\")\n",
        "print(\"  Categorical  → OneHotEncoder (drop='first')\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZ_18Y5NzUrF",
        "outputId": "acfd3b91-b375-4cae-c887-ee2c94e1a401"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "STEP 5 — Building preprocessing pipeline\n",
            "============================================================\n",
            "  Numeric      → StandardScaler\n",
            "  Categorical  → OneHotEncoder (drop='first')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"STEP 6 — Training baseline models\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# --- 6.1  Default Random Forest (no tuning) ---\n",
        "rf_default = Pipeline([\n",
        "    (\"preprocessor\", make_preprocessor()),\n",
        "    (\"classifier\",   RandomForestClassifier(\n",
        "        n_estimators     = 200,\n",
        "        max_depth        = 10,\n",
        "        min_samples_leaf = 5,\n",
        "        class_weight     = \"balanced\",\n",
        "        random_state     = 42,\n",
        "        n_jobs           = -1,\n",
        "    )),\n",
        "])\n",
        "print(\"  Training default Random Forest...\")\n",
        "rf_default.fit(X_train, y_train)\n",
        "rf_default_auc = roc_auc_score(y_test, rf_default.predict_proba(X_test)[:, 1])\n",
        "print(f\"  Done  →  Test AUC: {rf_default_auc:.4f}\")\n",
        "\n",
        "# --- 6.2  Logistic Regression (linear baseline) ---\n",
        "lr_pipeline = Pipeline([\n",
        "    (\"preprocessor\", make_preprocessor()),\n",
        "    (\"classifier\",   LogisticRegression(\n",
        "        class_weight = \"balanced\",\n",
        "        max_iter     = 1000,\n",
        "        random_state = 42,\n",
        "    )),\n",
        "])\n",
        "print(\"  Training Logistic Regression...\")\n",
        "lr_pipeline.fit(X_train, y_train)\n",
        "lr_auc = roc_auc_score(y_test, lr_pipeline.predict_proba(X_test)[:, 1])\n",
        "print(f\"  Done  →  Test AUC: {lr_auc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_Q--k9Zz5ww",
        "outputId": "ef04c7ba-69bf-4654-81b2-2e2e1108d3b3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "STEP 6 — Training baseline models\n",
            "============================================================\n",
            "  Training default Random Forest...\n",
            "  Done  →  Test AUC: 0.9746\n",
            "  Training Logistic Regression...\n",
            "  Done  →  Test AUC: 0.9746\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"STEP 7 — Hyperparameter tuning (RandomizedSearchCV)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# --- 7.1  Define the search space ---\n",
        "# All keys are prefixed \"classifier__\" because they sit inside a Pipeline.\n",
        "param_distributions = {\n",
        "\n",
        "    # Number of trees — more = more stable predictions, slower to train\n",
        "    \"classifier__n_estimators\":       [100, 200, 300, 500],\n",
        "\n",
        "    # Maximum tree depth — primary regularisation lever\n",
        "    # None = trees grow until pure leaves (risk of overfitting)\n",
        "    \"classifier__max_depth\":          [5, 8, 10, 15, 20, None],\n",
        "\n",
        "    # Minimum samples required to attempt a node split\n",
        "    \"classifier__min_samples_split\":  [2, 5, 10, 20],\n",
        "\n",
        "    # Minimum samples required at a leaf — smooths decision boundary\n",
        "    \"classifier__min_samples_leaf\":   [1, 2, 5, 10],\n",
        "\n",
        "    # Features considered at each split — controls tree diversity\n",
        "    # \"sqrt\" is the RF default; \"log2\" is more aggressive; floats = fraction\n",
        "    \"classifier__max_features\":       [\"sqrt\", \"log2\", 0.5, 0.8],\n",
        "\n",
        "    # Bootstrap sampling — False uses full training set for each tree\n",
        "    \"classifier__bootstrap\":          [True, False],\n",
        "\n",
        "    # Class weighting — critical for the 63.7% churn imbalance\n",
        "    # \"balanced_subsample\" reweights within each bootstrap sample\n",
        "    \"classifier__class_weight\":       [\"balanced\", \"balanced_subsample\"],\n",
        "}\n",
        "\n",
        "total_combinations = (\n",
        "    len(param_distributions[\"classifier__n_estimators\"])\n",
        "    * len(param_distributions[\"classifier__max_depth\"])\n",
        "    * len(param_distributions[\"classifier__min_samples_split\"])\n",
        "    * len(param_distributions[\"classifier__min_samples_leaf\"])\n",
        "    * len(param_distributions[\"classifier__max_features\"])\n",
        "    * len(param_distributions[\"classifier__bootstrap\"])\n",
        "    * len(param_distributions[\"classifier__class_weight\"])\n",
        ")\n",
        "\n",
        "# --- 7.2  Cross-validation strategy ---\n",
        "# StratifiedKFold preserves the churn ratio in every fold — essential for\n",
        "# imbalanced datasets. 5 folds gives stable estimates without excessive runtime.\n",
        "cv_strategy = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# --- 7.3  Build the tuning pipeline ---\n",
        "tuning_pipeline = Pipeline([\n",
        "    (\"preprocessor\", make_preprocessor()),\n",
        "    (\"classifier\",   RandomForestClassifier(random_state=42, n_jobs=-1)),\n",
        "])\n",
        "\n",
        "# --- 7.4  Run RandomizedSearchCV ---\n",
        "# n_iter=50 samples 50 random combinations from the full space — sufficient\n",
        "# to identify high-performing regions without exhaustive grid search.\n",
        "# refit=True means the best estimator is automatically refit on the full\n",
        "# training set and is ready to predict straight away.\n",
        "print(f\"  Search space:\")\n",
        "print(f\"    Parameters          : {len(param_distributions)}\")\n",
        "print(f\"    Total combinations  : {total_combinations:,}\")\n",
        "print(f\"    Random trials       : 50\")\n",
        "print(f\"    CV folds            : 5 (StratifiedKFold)\")\n",
        "print(f\"    Scoring metric      : AUC-ROC\")\n",
        "print(f\"  Running search — this takes 1–3 minutes...\")\n",
        "\n",
        "t0 = time.time()\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator           = tuning_pipeline,\n",
        "    param_distributions = param_distributions,\n",
        "    n_iter              = 50,\n",
        "    scoring             = \"roc_auc\",\n",
        "    cv                  = cv_strategy,\n",
        "    refit               = True,\n",
        "    return_train_score  = True,\n",
        "    random_state        = 42,\n",
        "    n_jobs              = -1,\n",
        "    verbose             = 0,\n",
        ")\n",
        "random_search.fit(X_train, y_train)\n",
        "tuning_time = time.time() - t0\n",
        "\n",
        "# --- 7.5  Extract results ---\n",
        "rf_tuned    = random_search.best_estimator_\n",
        "best_params = random_search.best_params_\n",
        "best_cv_auc = random_search.best_score_\n",
        "rf_tuned_auc = roc_auc_score(y_test, rf_tuned.predict_proba(X_test)[:, 1])\n",
        "\n",
        "print(f\"  Completed in {tuning_time:.0f}s\")\n",
        "print(f\"\\n  Best CV AUC (5-fold) : {best_cv_auc:.4f}\")\n",
        "print(f\"  Tuned test AUC       : {rf_tuned_auc:.4f}\")\n",
        "print(f\"  Default test AUC     : {rf_default_auc:.4f}\")\n",
        "delta = rf_tuned_auc - rf_default_auc\n",
        "print(f\"  Improvement          : {'+' if delta >= 0 else ''}{delta*100:.3f} pp\")\n",
        "\n",
        "print(f\"\\n  Best hyperparameters:\")\n",
        "for param, value in sorted(best_params.items()):\n",
        "    print(f\"    {param.replace('classifier__', ''):<25} : {value}\")\n",
        "\n",
        "# --- 7.6  Save all 50 trial results ---\n",
        "results_df = pd.DataFrame(random_search.cv_results_)\n",
        "keep_cols  = (\n",
        "    [c for c in results_df.columns if c.startswith(\"param_\")]\n",
        "    + [\"mean_test_score\", \"std_test_score\", \"mean_train_score\", \"rank_test_score\"]\n",
        ")\n",
        "results_df = (\n",
        "    results_df[keep_cols]\n",
        "    .rename(columns=lambda c: c.replace(\"param_classifier__\", \"\"))\n",
        "    .sort_values(\"rank_test_score\")\n",
        "    .reset_index(drop=True)\n",
        ")\n",
        "results_path = os.path.join(OUTPUT_DIR, \"tuning_results.csv\")\n",
        "results_df.to_csv(results_path, index=False)\n",
        "print(f\"\\n  All 50 trial results saved: {results_path}\")\n",
        "\n",
        "# --- 7.7  Cross-validate tuned model to confirm generalisation ---\n",
        "print(f\"\\n  5-fold CV on tuned model (overfitting check):\")\n",
        "cv_scores = cross_val_score(\n",
        "    rf_tuned, X_train, y_train,\n",
        "    cv=cv_strategy, scoring=\"roc_auc\", n_jobs=-1\n",
        ")\n",
        "print(f\"    Fold AUCs : {[round(s, 4) for s in cv_scores]}\")\n",
        "print(f\"    Mean AUC  : {cv_scores.mean():.4f}\")\n",
        "print(f\"    Std AUC   : {cv_scores.std():.4f}  \"\n",
        "      f\"({'stable' if cv_scores.std() < 0.02 else 'high variance — review'})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16T6VSXVz6nB",
        "outputId": "83babce7-ae42-449d-b1b0-d8b36f3138a2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "STEP 7 — Hyperparameter tuning (RandomizedSearchCV)\n",
            "============================================================\n",
            "  Search space:\n",
            "    Parameters          : 7\n",
            "    Total combinations  : 6,144\n",
            "    Random trials       : 50\n",
            "    CV folds            : 5 (StratifiedKFold)\n",
            "    Scoring metric      : AUC-ROC\n",
            "  Running search — this takes 1–3 minutes...\n",
            "  Completed in 896s\n",
            "\n",
            "  Best CV AUC (5-fold) : 0.9818\n",
            "  Tuned test AUC       : 0.9753\n",
            "  Default test AUC     : 0.9746\n",
            "  Improvement          : +0.070 pp\n",
            "\n",
            "  Best hyperparameters:\n",
            "    bootstrap                 : True\n",
            "    class_weight              : balanced_subsample\n",
            "    max_depth                 : None\n",
            "    max_features              : 0.5\n",
            "    min_samples_leaf          : 10\n",
            "    min_samples_split         : 20\n",
            "    n_estimators              : 200\n",
            "\n",
            "  All 50 trial results saved: /content/model_outputs/tuning_results.csv\n",
            "\n",
            "  5-fold CV on tuned model (overfitting check):\n",
            "    Fold AUCs : [np.float64(0.982), np.float64(0.9833), np.float64(0.975), np.float64(0.9841), np.float64(0.9845)]\n",
            "    Mean AUC  : 0.9818\n",
            "    Std AUC   : 0.0035  (stable)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"STEP 8 — Model evaluation\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "rf_tuned_proba   = rf_tuned.predict_proba(X_test)[:, 1]\n",
        "rf_tuned_pred    = rf_tuned.predict(X_test)\n",
        "rf_default_proba = rf_default.predict_proba(X_test)[:, 1]\n",
        "rf_default_pred  = rf_default.predict(X_test)\n",
        "lr_proba         = lr_pipeline.predict_proba(X_test)[:, 1]\n",
        "lr_pred          = lr_pipeline.predict(X_test)\n",
        "\n",
        "def compute_metrics(y_true, y_pred, y_proba):\n",
        "    n_decile = max(1, int(len(y_true) * 0.10))\n",
        "    top_idx  = np.argsort(y_proba)[::-1][:n_decile]\n",
        "    return {\n",
        "        \"auc\"       : roc_auc_score(y_true, y_proba),\n",
        "        \"precision\" : precision_score(y_true, y_pred),\n",
        "        \"recall\"    : recall_score(y_true, y_pred),\n",
        "        \"f1\"        : f1_score(y_true, y_pred),\n",
        "        \"prec_d10\"  : y_true.iloc[top_idx].mean(),\n",
        "    }\n",
        "\n",
        "m_tuned   = compute_metrics(y_test, rf_tuned_pred,   rf_tuned_proba)\n",
        "m_default = compute_metrics(y_test, rf_default_pred,  rf_default_proba)\n",
        "m_lr      = compute_metrics(y_test, lr_pred,          lr_proba)\n",
        "\n",
        "metric_rows = [\n",
        "    (\"AUC-ROC\",              \"auc\"),\n",
        "    (\"Precision\",            \"precision\"),\n",
        "    (\"Recall\",               \"recall\"),\n",
        "    (\"F1 Score\",             \"f1\"),\n",
        "    (\"Precision @ Decile 1\", \"prec_d10\"),\n",
        "]\n",
        "\n",
        "print(f\"\\n  {'Metric':<28} {'RF Tuned':>12} {'RF Default':>12} {'Log Reg':>12}\")\n",
        "print(f\"  {'-'*66}\")\n",
        "for label, key in metric_rows:\n",
        "    print(f\"  {label:<28} {m_tuned[key]:>12.4f} \"\n",
        "          f\"{m_default[key]:>12.4f} {m_lr[key]:>12.4f}\")\n",
        "\n",
        "if m_tuned[\"auc\"] >= 0.75:\n",
        "    print(f\"\\n  ✓ Tuned AUC {m_tuned['auc']:.4f} meets target threshold of 0.75\")\n",
        "else:\n",
        "    print(f\"\\n  ✗ Tuned AUC {m_tuned['auc']:.4f} below target — review features\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UrXfvYlF1c93",
        "outputId": "371fa7b8-94d0-4db6-d559-03b3f554512f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "STEP 8 — Model evaluation\n",
            "============================================================\n",
            "\n",
            "  Metric                           RF Tuned   RF Default      Log Reg\n",
            "  ------------------------------------------------------------------\n",
            "  AUC-ROC                            0.9753       0.9746       0.9746\n",
            "  Precision                          0.9377       0.9412       0.9487\n",
            "  Recall                             0.9451       0.9294       0.8995\n",
            "  F1 Score                           0.9414       0.9352       0.9234\n",
            "  Precision @ Decile 1               1.0000       1.0000       1.0000\n",
            "\n",
            "  ✓ Tuned AUC 0.9753 meets target threshold of 0.75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"STEP 9 — Feature importance (tuned model)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "tuned_clf    = rf_tuned.named_steps[\"classifier\"]\n",
        "ohe_feats    = (rf_tuned.named_steps[\"preprocessor\"]\n",
        "                .named_transformers_[\"cat\"]\n",
        "                .get_feature_names_out(CATEGORICAL_FEATURES))\n",
        "all_features = NUMERIC_FEATURES + list(ohe_feats)\n",
        "\n",
        "importance_df = pd.DataFrame({\n",
        "    \"feature\":    all_features,\n",
        "    \"importance\": tuned_clf.feature_importances_,\n",
        "}).sort_values(\"importance\", ascending=False).reset_index(drop=True)\n",
        "\n",
        "print(\"\\n  Top 10 most important features:\")\n",
        "for _, row in importance_df.head(10).iterrows():\n",
        "    bar = \"█\" * int(row[\"importance\"] * 200)\n",
        "    print(f\"    {row['feature']:<30} {row['importance']:.4f}  {bar}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "trNLpny02dq8",
        "outputId": "290971ed-542c-4569-82bb-46b3f5e3a0e6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "STEP 9 — Feature importance (tuned model)\n",
            "============================================================\n",
            "\n",
            "  Top 10 most important features:\n",
            "    recency_days                   0.5162  ███████████████████████████████████████████████████████████████████████████████████████████████████████\n",
            "    R_score                        0.2514  ██████████████████████████████████████████████████\n",
            "    spend_per_order_ratio          0.0798  ███████████████\n",
            "    frequency                      0.0342  ██████\n",
            "    monthly_order_rate             0.0325  ██████\n",
            "    tenure_days                    0.0191  ███\n",
            "    F_score                        0.0147  ██\n",
            "    avg_order_value                0.0075  █\n",
            "    monetary                       0.0070  █\n",
            "    total_discounts                0.0063  █\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"STEP 10 — Generating evaluation charts\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "NAVY  = \"#1B2A4A\"\n",
        "AMBER = \"#F5A623\"\n",
        "GREEN = \"#10B981\"\n",
        "RED   = \"#EF4444\"\n",
        "TEAL  = \"#0EA5E9\"\n",
        "GRAY  = \"#6B7280\"\n",
        "\n",
        "fig = plt.figure(figsize=(20, 14))\n",
        "fig.patch.set_facecolor(\"white\")\n",
        "gs  = gridspec.GridSpec(2, 3, figure=fig, hspace=0.45, wspace=0.35)\n",
        "\n",
        "# ── Chart 1: ROC Curves — all three models ───────────────────────────────────\n",
        "ax1 = fig.add_subplot(gs[0, 0])\n",
        "for proba, label, colour, ls in [\n",
        "    (rf_tuned_proba,   f\"RF Tuned   (AUC={m_tuned['auc']:.3f})\",   NAVY,  \"-\"),\n",
        "    (rf_default_proba, f\"RF Default (AUC={m_default['auc']:.3f})\", AMBER, \"--\"),\n",
        "    (lr_proba,         f\"Log Reg    (AUC={m_lr['auc']:.3f})\",      TEAL,  \":\"),\n",
        "]:\n",
        "    fpr, tpr, _ = roc_curve(y_test, proba)\n",
        "    ax1.plot(fpr, tpr, color=colour, lw=2, linestyle=ls, label=label)\n",
        "ax1.plot([0,1], [0,1], color=GRAY, lw=1, linestyle=\":\")\n",
        "ax1.axhline(0.75, color=GREEN, lw=1, linestyle=\"--\", alpha=0.5, label=\"Target (0.75)\")\n",
        "ax1.set_title(\"ROC Curves — All Models\", fontsize=12, fontweight=\"bold\",\n",
        "              color=NAVY, pad=10)\n",
        "ax1.set_xlabel(\"False Positive Rate\", fontsize=10, color=GRAY)\n",
        "ax1.set_ylabel(\"True Positive Rate\",  fontsize=10, color=GRAY)\n",
        "ax1.legend(fontsize=8, framealpha=0.9)\n",
        "ax1.set_facecolor(\"#FAFBFD\")\n",
        "ax1.grid(True, alpha=0.3, color=GRAY)\n",
        "\n",
        "# ── Chart 2: Confusion Matrix — tuned model ──────────────────────────────────\n",
        "ax2 = fig.add_subplot(gs[0, 1])\n",
        "cm = confusion_matrix(y_test, rf_tuned_pred)\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "            xticklabels=[\"Pred: Retained\", \"Pred: Churned\"],\n",
        "            yticklabels=[\"Act:  Retained\", \"Act:  Churned\"],\n",
        "            ax=ax2, linewidths=0.5, linecolor=\"white\",\n",
        "            annot_kws={\"size\": 13, \"weight\": \"bold\"})\n",
        "ax2.set_title(\"Confusion Matrix — RF Tuned\", fontsize=12, fontweight=\"bold\",\n",
        "              color=NAVY, pad=10)\n",
        "ax2.tick_params(colors=GRAY, labelsize=9)\n",
        "\n",
        "# ── Chart 3: Metric Comparison Bar ───────────────────────────────────────────\n",
        "ax3 = fig.add_subplot(gs[0, 2])\n",
        "metric_labels_short = [\"AUC-ROC\", \"Precision\", \"Recall\", \"F1\"]\n",
        "metric_keys_short   = [\"auc\", \"precision\", \"recall\", \"f1\"]\n",
        "x     = np.arange(len(metric_labels_short))\n",
        "width = 0.25\n",
        "\n",
        "for i, (m_dict, label, colour) in enumerate([\n",
        "    (m_tuned,   \"RF Tuned\",   NAVY),\n",
        "    (m_default, \"RF Default\", AMBER),\n",
        "    (m_lr,      \"Log Reg\",    TEAL),\n",
        "]):\n",
        "    vals = [m_dict[k] for k in metric_keys_short]\n",
        "    bars = ax3.bar(x + (i - 1) * width, vals, width,\n",
        "                   label=label, color=colour, alpha=0.9, edgecolor=\"white\")\n",
        "    for bar in bars:\n",
        "        ax3.text(bar.get_x() + bar.get_width() / 2,\n",
        "                 bar.get_height() + 0.015,\n",
        "                 f\"{bar.get_height():.2f}\",\n",
        "                 ha=\"center\", va=\"bottom\", fontsize=7,\n",
        "                 color=colour, fontweight=\"bold\")\n",
        "\n",
        "ax3.axhline(0.75, color=GREEN, lw=1.5, linestyle=\"--\",\n",
        "            label=\"Target (0.75)\", alpha=0.8)\n",
        "ax3.set_title(\"Model Comparison\", fontsize=12, fontweight=\"bold\",\n",
        "              color=NAVY, pad=10)\n",
        "ax3.set_xticks(x)\n",
        "ax3.set_xticklabels(metric_labels_short, fontsize=9, color=GRAY)\n",
        "ax3.set_ylim(0, 1.15)\n",
        "ax3.set_facecolor(\"#FAFBFD\")\n",
        "ax3.legend(fontsize=8)\n",
        "ax3.grid(True, axis=\"y\", alpha=0.3, color=GRAY)\n",
        "ax3.tick_params(colors=GRAY)\n",
        "\n",
        "# ── Chart 4: Top 15 Feature Importances ──────────────────────────────────────\n",
        "ax4 = fig.add_subplot(gs[1, :2])\n",
        "top15   = importance_df.head(15).sort_values(\"importance\")\n",
        "colours = [AMBER if i >= 12 else NAVY for i in range(len(top15))]\n",
        "bars    = ax4.barh(top15[\"feature\"], top15[\"importance\"],\n",
        "                   color=colours, alpha=0.9, edgecolor=\"white\")\n",
        "ax4.set_title(\"Top 15 Feature Importances — RF Tuned\",\n",
        "              fontsize=12, fontweight=\"bold\", color=NAVY, pad=10)\n",
        "ax4.set_xlabel(\"Importance\", fontsize=10, color=GRAY)\n",
        "ax4.set_facecolor(\"#FAFBFD\")\n",
        "ax4.grid(True, axis=\"x\", alpha=0.3, color=GRAY)\n",
        "ax4.tick_params(colors=GRAY, labelsize=9)\n",
        "for bar in bars:\n",
        "    ax4.text(bar.get_width() + 0.001,\n",
        "             bar.get_y() + bar.get_height() / 2,\n",
        "             f\"{bar.get_width():.4f}\",\n",
        "             va=\"center\", fontsize=8, color=GRAY)\n",
        "\n",
        "# ── Chart 5: Tuning — CV AUC distribution across 50 trials ──────────────────\n",
        "ax5 = fig.add_subplot(gs[1, 2])\n",
        "trial_aucs = results_df[\"mean_test_score\"].dropna().values\n",
        "ax5.hist(trial_aucs, bins=20, color=NAVY, alpha=0.8, edgecolor=\"white\")\n",
        "ax5.axvline(rf_default_auc, color=AMBER, lw=2, linestyle=\"--\",\n",
        "            label=f\"Default  ({rf_default_auc:.4f})\")\n",
        "ax5.axvline(rf_tuned_auc,   color=GREEN, lw=2, linestyle=\"-\",\n",
        "            label=f\"Tuned    ({rf_tuned_auc:.4f})\")\n",
        "ax5.set_title(\"Tuning — CV AUC Distribution\\n(50 Random Trials)\",\n",
        "              fontsize=12, fontweight=\"bold\", color=NAVY, pad=10)\n",
        "ax5.set_xlabel(\"Mean CV AUC (5-fold)\", fontsize=10, color=GRAY)\n",
        "ax5.set_ylabel(\"Trial Count\",          fontsize=10, color=GRAY)\n",
        "ax5.legend(fontsize=9)\n",
        "ax5.set_facecolor(\"#FAFBFD\")\n",
        "ax5.grid(True, alpha=0.3, color=GRAY)\n",
        "ax5.tick_params(colors=GRAY)\n",
        "\n",
        "# ── Suptitle & footer ─────────────────────────────────────────────────────────\n",
        "fig.suptitle(\n",
        "    \"E-Commerce Customer Churn Prediction — Model Evaluation (v2.0)\",\n",
        "    fontsize=16, fontweight=\"bold\", color=NAVY, y=1.01\n",
        ")\n",
        "fig.text(\n",
        "    0.5, -0.01,\n",
        "    (f\"Josiah Nwosu  |  February 2026  |  \"\n",
        "     f\"RF Tuned: n_est={best_params.get('classifier__n_estimators','?')}  \"\n",
        "     f\"max_depth={best_params.get('classifier__max_depth','?')}  \"\n",
        "     f\"min_leaf={best_params.get('classifier__min_samples_leaf','?')}  \"\n",
        "     f\"max_feat={best_params.get('classifier__max_features','?')}\"),\n",
        "    ha=\"center\", fontsize=8, color=GRAY,\n",
        ")\n",
        "\n",
        "chart_path = os.path.join(OUTPUT_DIR, \"model_evaluation.png\")\n",
        "fig.savefig(chart_path, dpi=150, bbox_inches=\"tight\", facecolor=\"white\")\n",
        "plt.close()\n",
        "print(f\"  Saved: {chart_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cFGEfjc4Vgf",
        "outputId": "2cdfe711-755c-467b-bab3-c4826d668fc8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "STEP 10 — Generating evaluation charts\n",
            "============================================================\n",
            "  Saved: /content/model_outputs/model_evaluation.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"STEP 11 — Exporting churn predictions (tuned model)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "all_proba = rf_tuned.predict_proba(X)[:, 1]\n",
        "all_pred  = rf_tuned.predict(X)\n",
        "\n",
        "predictions = df[[\n",
        "    \"customer_id\", \"segment\", \"state\", \"age_group\",\n",
        "    \"churned\", \"recency_days\", \"frequency\", \"monetary\",\n",
        "    \"avg_order_value\", \"avg_review_score\", \"refund_rate\",\n",
        "    \"R_score\", \"F_score\", \"M_score\", \"RFM_score\",\n",
        "]].copy()\n",
        "\n",
        "predictions[\"churn_probability\"]      = np.round(all_proba, 4)\n",
        "predictions[\"churn_predicted\"]        = all_pred\n",
        "predictions[\"revenue_at_risk_3m_ngn\"] = np.round(\n",
        "    (df[\"monetary\"] / df[\"frequency\"].clip(lower=1)) * 3, 0\n",
        ")\n",
        "\n",
        "def health_status(row):\n",
        "    if row[\"churned\"]           == 1:    return \"Churned\"\n",
        "    if row[\"churn_probability\"] >= 0.75: return \"High Risk\"\n",
        "    if row[\"churn_probability\"] >= 0.50: return \"Medium Risk\"\n",
        "    if row[\"churn_probability\"] >= 0.25: return \"Low Risk\"\n",
        "    return \"Active\"\n",
        "\n",
        "predictions[\"health_status\"] = predictions.apply(health_status, axis=1)\n",
        "predictions = predictions.sort_values(\"revenue_at_risk_3m_ngn\", ascending=False)\n",
        "\n",
        "pred_path = os.path.join(OUTPUT_DIR, \"churn_predictions.csv\")\n",
        "predictions.to_csv(pred_path, index=False)\n",
        "\n",
        "print(f\"  Saved : {pred_path}\")\n",
        "print(f\"  Rows  : {len(predictions):,}\")\n",
        "print(\"\\n  Health status distribution:\")\n",
        "print(predictions[\"health_status\"].value_counts().to_string())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_s53Tn946EC7",
        "outputId": "6cd33e69-b7d4-4dfc-c502-4c6a3c94a6a4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "STEP 11 — Exporting churn predictions (tuned model)\n",
            "============================================================\n",
            "  Saved : /content/model_outputs/churn_predictions.csv\n",
            "  Rows  : 5,000\n",
            "\n",
            "  Health status distribution:\n",
            "health_status\n",
            "Churned        3184\n",
            "Active         1544\n",
            "Low Risk        137\n",
            "Medium Risk      95\n",
            "High Risk        40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"STEP 12 — Saving classification report\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "report      = classification_report(\n",
        "    y_test, rf_tuned_pred,\n",
        "    target_names=[\"Retained (0)\", \"Churned (1)\"]\n",
        ")\n",
        "report_path = os.path.join(OUTPUT_DIR, \"classification_report.txt\")\n",
        "with open(report_path, \"w\") as f:\n",
        "    f.write(\"E-COMMERCE CUSTOMER CHURN PREDICTION\\n\")\n",
        "    f.write(\"Classification Report — RF Tuned (v2.0)\\n\")\n",
        "    f.write(\"Josiah Nwosu | February 2026\\n\")\n",
        "    f.write(\"=\" * 55 + \"\\n\\n\")\n",
        "    f.write(report)\n",
        "print(f\"  Saved: {report_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCpwznd46JcH",
        "outputId": "d9ed7428-77d6-49cd-d558-435aef624b92"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "STEP 12 — Saving classification report\n",
            "============================================================\n",
            "  Saved: /content/model_outputs/classification_report.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"STEP 13 — Saving model summary\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "summary_path = os.path.join(OUTPUT_DIR, \"model_summary.txt\")\n",
        "with open(summary_path, \"w\") as f:\n",
        "    f.write(\"=\" * 60 + \"\\n\")\n",
        "    f.write(\"E-COMMERCE CUSTOMER CHURN PREDICTION\\n\")\n",
        "    f.write(\"Model Summary — v2.0 (with hyperparameter tuning)\\n\")\n",
        "    f.write(\"Author : Josiah Nwosu\\n\")\n",
        "    f.write(\"Date   : February 2026\\n\")\n",
        "    f.write(\"=\" * 60 + \"\\n\\n\")\n",
        "\n",
        "    f.write(\"DATASET\\n\")\n",
        "    f.write(\"-\" * 40 + \"\\n\")\n",
        "    f.write(f\"Total customers      : {len(df):,}\\n\")\n",
        "    f.write(f\"Churned  (label=1)   : {df['churned'].sum():,} ({df['churned'].mean()*100:.1f}%)\\n\")\n",
        "    f.write(f\"Retained (label=0)   : {(df['churned']==0).sum():,} ({(df['churned']==0).mean()*100:.1f}%)\\n\")\n",
        "    f.write(f\"Train set            : {len(X_train):,} customers\\n\")\n",
        "    f.write(f\"Test  set            : {len(X_test):,}  customers\\n\")\n",
        "    f.write(f\"Split method         : Stratified 80/20\\n\\n\")\n",
        "\n",
        "    f.write(\"TUNING CONFIGURATION\\n\")\n",
        "    f.write(\"-\" * 40 + \"\\n\")\n",
        "    f.write(f\"Method               : RandomizedSearchCV\\n\")\n",
        "    f.write(f\"Trials (n_iter)      : 50\\n\")\n",
        "    f.write(f\"CV strategy          : StratifiedKFold (5 folds)\\n\")\n",
        "    f.write(f\"Scoring metric       : AUC-ROC\\n\")\n",
        "    f.write(f\"Search time          : {tuning_time:.0f}s\\n\")\n",
        "    f.write(f\"Total combinations   : {total_combinations:,}\\n\\n\")\n",
        "\n",
        "    f.write(\"BEST HYPERPARAMETERS FOUND\\n\")\n",
        "    f.write(\"-\" * 40 + \"\\n\")\n",
        "    for param, value in sorted(best_params.items()):\n",
        "        f.write(f\"  {param.replace('classifier__', ''):<25} : {value}\\n\")\n",
        "    f.write(\"\\n\")\n",
        "\n",
        "    f.write(\"CV STABILITY — TUNED MODEL\\n\")\n",
        "    f.write(\"-\" * 40 + \"\\n\")\n",
        "    for i, s in enumerate(cv_scores, 1):\n",
        "        f.write(f\"  Fold {i} AUC : {s:.4f}\\n\")\n",
        "    f.write(f\"  Mean      : {cv_scores.mean():.4f}\\n\")\n",
        "    f.write(f\"  Std       : {cv_scores.std():.4f}  \"\n",
        "            f\"({'stable' if cv_scores.std() < 0.02 else 'high variance'})\\n\\n\")\n",
        "\n",
        "    f.write(\"EVALUATION RESULTS\\n\")\n",
        "    f.write(\"-\" * 40 + \"\\n\")\n",
        "    f.write(f\"{'Metric':<28} {'RF Tuned':>10} {'RF Default':>12} {'Log Reg':>10}\\n\")\n",
        "    for label, key in metric_rows:\n",
        "        f.write(f\"  {label:<26} {m_tuned[key]:>10.4f} \"\n",
        "                f\"{m_default[key]:>12.4f} {m_lr[key]:>10.4f}\\n\")\n",
        "    f.write(\"\\n\")\n",
        "\n",
        "    f.write(\"TOP 10 MOST IMPORTANT FEATURES — TUNED MODEL\\n\")\n",
        "    f.write(\"-\" * 40 + \"\\n\")\n",
        "    for i, row in importance_df.head(10).iterrows():\n",
        "        f.write(f\"  {i+1:>2}. {row['feature']:<30} {row['importance']:.4f}\\n\")\n",
        "\n",
        "    f.write(\"\\nOUTPUT FILES\\n\")\n",
        "    f.write(\"-\" * 40 + \"\\n\")\n",
        "    f.write(\"  churn_predictions.csv     — churn scores for all 5,000 customers\\n\")\n",
        "    f.write(\"  model_evaluation.png      — ROC curves, confusion matrix, tuning chart\\n\")\n",
        "    f.write(\"  tuning_results.csv        — all 50 RandomizedSearchCV trial results\\n\")\n",
        "    f.write(\"  classification_report.txt — per-class precision, recall, F1\\n\")\n",
        "    f.write(\"  model_summary.txt         — this file\\n\")\n",
        "\n",
        "print(f\"  Saved: {summary_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIVbdrco6OqF",
        "outputId": "b6a2e741-1757-46ad-abd5-0db775565101"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "STEP 13 — Saving model summary\n",
            "============================================================\n",
            "  Saved: /content/model_outputs/model_summary.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"ALL STEPS COMPLETE\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\n  RF Default AUC   : {m_default['auc']:.4f}\")\n",
        "print(f\"  RF Tuned   AUC   : {m_tuned['auc']:.4f}  ← final model\")\n",
        "print(f\"  Log Reg    AUC   : {m_lr['auc']:.4f}\")\n",
        "print(f\"  CV Mean AUC      : {cv_scores.mean():.4f}  (std: {cv_scores.std():.4f})\")\n",
        "print(f\"\\n  Best params      : {best_params}\")\n",
        "print(f\"\\n  Predictions      : {pred_path}\")\n",
        "print(f\"  Charts           : {chart_path}\")\n",
        "print(f\"  Tuning results   : {results_path}\")\n",
        "print(\"=\" * 60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BuHldaVj6h9I",
        "outputId": "e3bc679a-b205-4571-c888-325abf1f95ad"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "ALL STEPS COMPLETE\n",
            "============================================================\n",
            "\n",
            "  RF Default AUC   : 0.9746\n",
            "  RF Tuned   AUC   : 0.9753  ← final model\n",
            "  Log Reg    AUC   : 0.9746\n",
            "  CV Mean AUC      : 0.9818  (std: 0.0035)\n",
            "\n",
            "  Best params      : {'classifier__n_estimators': 200, 'classifier__min_samples_split': 20, 'classifier__min_samples_leaf': 10, 'classifier__max_features': 0.5, 'classifier__max_depth': None, 'classifier__class_weight': 'balanced_subsample', 'classifier__bootstrap': True}\n",
            "\n",
            "  Predictions      : /content/model_outputs/churn_predictions.csv\n",
            "  Charts           : /content/model_outputs/model_evaluation.png\n",
            "  Tuning results   : /content/model_outputs/tuning_results.csv\n",
            "\n",
            "  Next step: Load churn_predictions.csv into Power BI\n",
            "============================================================\n"
          ]
        }
      ]
    }
  ]
}